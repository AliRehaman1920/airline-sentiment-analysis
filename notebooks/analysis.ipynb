{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ad1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "\"\"\" src imports \"\"\"\n",
    "\n",
    "from src.data_processing import clean_data, rm_domain_words\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e3e61",
   "metadata": {},
   "source": [
    "selecting only sentiment and text columns for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db6dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "df = pd.read_csv('../data/raw/Tweets-train.csv')\n",
    "\n",
    "sentiment = df['airline_sentiment']\n",
    "text = df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884691fc",
   "metadata": {},
   "source": [
    "observing 10 samples of each sentiment to identify the words/puncts/emoticons needed to be preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = df[df['airline_sentiment'] == 'positive'].sample(10)\n",
    "neg = df[df['airline_sentiment'] == 'negative'].sample(10)\n",
    "neu = df[df['airline_sentiment'] == 'neutral'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8780cd",
   "metadata": {},
   "source": [
    "cleaning the text column using clean_data function from src/data_processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a1fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = clean_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b333c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" top 15 words from each sentiment before removing domain specifc words \"\"\"\n",
    "\n",
    "sentiments = ['positive', 'negative', 'neutral']\n",
    "\n",
    "tweets = {sentiment: df.loc[df['airline_sentiment'] == sentiment, 'cleaned_text'] for sentiment in sentiments}\n",
    "\n",
    "words = {sentiment: ' '.join(tweets[sentiment]).split() for sentiment in sentiments}\n",
    "\n",
    "counts = {sentiment: Counter(words[sentiment]) for sentiment in sentiments}\n",
    "\n",
    "top_15 = {sentiment: counts[sentiment].most_common(15) for sentiment in sentiments}\n",
    "\n",
    "for sentiment in sentiments:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Top 15 words for {sentiment}\")\n",
    "    print('='*50)\n",
    "    for word, count in top_15[sentiment]:\n",
    "        print(f\"{word}:  {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a17a0a",
   "metadata": {},
   "source": [
    "removing domain specific words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27630979",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsw = [\n",
    "    'americanair', 'united', 'delta',\n",
    "    'southwestair', 'jetblue', 'virginamerica',\n",
    "    'usairways', 'flight', 'plane'\n",
    "    ]   # dsw = domain specific words\n",
    "\n",
    "df['ds_removed'] = rm_domain_words(df['cleaned_text'], dsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" top 15 words from each sentiment after removing domain specifc words \"\"\"\n",
    "\n",
    "tweets1 = {sentiment: df.loc[df['airline_sentiment'] == sentiment, 'ds_removed'] for sentiment in sentiments}\n",
    "\n",
    "words1 = {sentiment: ' '.join(tweets1[sentiment]).split() for sentiment in sentiments}\n",
    "\n",
    "counts1 = {sentiment: Counter(words1[sentiment]) for sentiment in sentiments}\n",
    "\n",
    "top_15_1 = {sentiment: counts1[sentiment].most_common(15) for sentiment in sentiments}\n",
    "\n",
    "for sentiment in sentiments:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Top 15 words for {sentiment}\")\n",
    "    print('='*50)\n",
    "    for word, count in top_15_1[sentiment]:\n",
    "        print(f\"{word}:  {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a044121b",
   "metadata": {},
   "source": [
    "***after removing the domain specifc words, the change is minimal, as there are lot of other domain specifc words which aren't mentioned in the given list***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3edc27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
